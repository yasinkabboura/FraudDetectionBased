{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8WTE2LtS5rDR"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Dataset Generation\n",
        "np.random.seed(42)\n",
        "num_samples = 10000\n",
        "data = {\n",
        "    \"transaction_amount\": np.random.uniform(1, 15000, num_samples),\n",
        "    \"transaction_time\": np.random.uniform(0, 24, num_samples),\n",
        "}\n",
        "\n",
        "def generate_fraud_label(row):\n",
        "    amount = row[\"transaction_amount\"]\n",
        "    time = row[\"transaction_time\"]\n",
        "    if amount > 2000 and (22 <= time <= 24 or 0 <= time <= 6):\n",
        "        return 1\n",
        "    elif amount > 10000:\n",
        "        return np.random.choice([0, 1], p=[0.5, 0.5])\n",
        "    elif 22 <= time <= 24 or 0 <= time <= 6:\n",
        "        return np.random.choice([0, 1], p=[0.5, 0.5])\n",
        "    return 0\n",
        "\n",
        "data[\"fraudulent\"] = [generate_fraud_label(row) for _, row in pd.DataFrame(data).iterrows()]\n",
        "\n",
        "# Data Preparation\n",
        "df = pd.DataFrame(data)\n",
        "X = df[[\"transaction_amount\", \"transaction_time\"]].values\n",
        "y = df[\"fraudulent\"].values\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Model Construction with Functional API\n",
        "inputs = tf.keras.Input(shape=(2,), name=\"inputs\")\n",
        "x = tf.keras.layers.Dense(64, activation='relu', name='dense_1')(inputs)\n",
        "x = tf.keras.layers.Dense(32, activation='relu', name='dense_2')(x)\n",
        "outputs = tf.keras.layers.Dense(1, activation='sigmoid', name='outputs')(x)\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"fraud_model_v1\")\n",
        "\n",
        "# Compile and Train\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Initialize variables\n",
        "model.predict(np.zeros((1, 2)))\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=64,\n",
        "                    validation_data=(X_test, y_test))\n",
        "\n",
        "# Model Export\n",
        "model_dir = '/content/drive/My Drive/fraud_model/4'\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "@tf.function(input_signature=[tf.TensorSpec(shape=[None, 2], dtype=tf.float32)])\n",
        "def serve(inputs):\n",
        "    return {'predictions': model(inputs)}\n",
        "\n",
        "tf.saved_model.save(\n",
        "    model,\n",
        "    model_dir,\n",
        "    signatures={'serving_default': serve},\n",
        "    options=tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\n",
        ")\n",
        "\n",
        "# Verification\n",
        "print(\"\\n=== Model Inspection ===\")\n",
        "!saved_model_cli show --dir {model_dir} --all\n",
        "!saved_model_cli run --dir {model_dir} --tag_set serve --signature_def serving_default \\\n",
        "  --input_exprs \"inputs=np.zeros((1, 2))\"\n",
        "\n",
        "print(\"\\n=== Normalization Parameters ===\")\n",
        "print(f\"Amount: [{scaler.data_min_[0]}, {scaler.data_max_[0]}]\")\n",
        "print(f\"Time:   [{scaler.data_min_[1]}, {scaler.data_max_[1]}]\")"
      ]
    }
  ]
}